seed: 0
train: yes
eval: yes

# answer_prompt: ' A: '
# answer_prompt: ' The summary of the previous text is: '
answer_prompt: ' Summary: '
max_tokens: 2048
generate_max_new_tokens: 100

data:
  max_train: null
  max_test: 1000
  max_val: 1000

model:
  # name: "facebook/opt-350m"
  name: "facebook/opt-125m"

training:
  lr: 0.0002
  batch_size: 16
  batch_split_size: 2
  num_epochs: 10
  log_step: 10

testing:
  batch_size: 2
  log_step: 200
  n_generate: 10

peft:
  method: lora
